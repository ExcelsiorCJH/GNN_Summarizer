{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE Metric Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from models import BasicSummarizer\n",
    "from types_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Sentence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_path = '../../data/summary/data/train.json'\n",
    "with open(data_path, 'r', encoding='utf8') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = data[0]\n",
    "\n",
    "text1 = sample1['doc']\n",
    "summary1 = sample1['summaries']\n",
    "labels1 = sample1['labels']\n",
    "labels1 = labels1.split('\\n')\n",
    "labels1 = [int(label) for label in labels1]\n",
    "\n",
    "sentences1 = text1.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Summary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    docs = [entry[0] for entry in batch]\n",
    "    labels = [entry[1] for entry in batch]\n",
    "    \n",
    "    offsets = [0] + [len(doc) for doc in docs]\n",
    "        \n",
    "    return docs, offsets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data.\"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.data[idx]['doc'].split('\\n')\n",
    "        labels = self.data[idx]['labels'].split('\\n')\n",
    "        labels = [int(label) for label in labels]\n",
    "        \n",
    "        return sentences, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) dataset split (train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/summary/data/train.json'\n",
    "\n",
    "dataset = SummaryDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(dataset))\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - (train_size + valid_size)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset \\\n",
    "    = random_split(dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Dataloader for Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=32, \n",
    "                              shuffle=False, \n",
    "                              collate_fn=generate_batch)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, \n",
    "                              batch_size=32, \n",
    "                              shuffle=False,\n",
    "                              collate_fn=generate_batch)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                             batch_size=32, \n",
    "                             shuffle=False,\n",
    "                             collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, offsets, labels_list = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loads trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at C:\\Users\\korea\\.cache\\torch\\transformers\\dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = '../04_train_summarizer/save_weights/basicsumarizer_epoch=18_val_acc=0.62_lr005.pth'\n",
    "\n",
    "model = BasicSummarizer(in_dim=128,\n",
    "                        hidden_dim=64,\n",
    "                        out_dim=32,\n",
    "                        num_heads=2,\n",
    "                        num_classes=1).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(docs, offsets, labels_list)\n",
    "    preds = torch.sigmoid(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.cpu().numpy()\n",
    "preds = (preds > 0.555).astype(int)\n",
    "preds = preds.reshape((preds.shape[0], -1))\n",
    "preds_list = np.split(preds, offsets[1:-1], axis=1)\n",
    "preds_list = [row.reshape(-1).tolist() for row in preds_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGE Metric Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) save summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = './results/summ'\n",
    "gold_path = './results/gold'\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.mkdir(summary_path)\n",
    "\n",
    "if not os.path.exists(gold_path):\n",
    "    gold_exist = False\n",
    "    os.mkdir(gold_path)\n",
    "else:\n",
    "    gold_exist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_idx = 0\n",
    "rouge_scores = []\n",
    "for doc, preds, labels in zip(docs, preds_list, labels_list):\n",
    "    summ, gold = [], []\n",
    "    for sent, pred, label in zip(doc, preds, labels):\n",
    "        if pred == 1:\n",
    "            summ.append(sent)\n",
    "        elif label == 1:\n",
    "            gold.append(sent)\n",
    "    \n",
    "    summ = ' '.join(summ)\n",
    "    gold = ' '.join(gold)\n",
    "    \n",
    "    # write files\n",
    "    with open(f'{summary_path}/test_summ_{r_idx}.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(summ)\n",
    "    with open(f'{gold_path}/gold_summ_{r_idx}.txt', 'w', encoding='utf8') as f:\n",
    "        f.write(gold)\n",
    "    \n",
    "    # rouge score append\n",
    "    rouge_scores.append(scorer.score(gold, summ))\n",
    "    \n",
    "    r_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"by tahira yaqoob published : 06:21 est , 22 november 2012 updated : 02:52 est , 23 november 2012 a british woman has been sentenced to three months in a dubai jail followed by deportation for having drunken sex in the back of a taxi in the city rebecca blake , 29 , had been arrested earlier this year after partially stripping off in the back of the cab after a 10 - hour drinking binge irishman conor mcredmond , 28 , with whom she was caught , was also convicted and received the same sentence , despite dna tests to find evidence of intercourse coming back negative recruitment consultant blake , from dorking in surrey , was arrested on may 4 after first meeting conor mcredmond just hours earlier their taxi driver alerted police after spotting blake in his rearview mirror with her top off , straddling mcredmond and â\\x80\\x98 making the sounds of a woman having sex â\\x80\\x99 jailed : ms rebecca blake ( second right ) and mr conor mcredmond ( left ) chat with their lawyer shaker al shammary ( second left ) and ms rebecca blake 's sister natasha todd ( far right ) outside the dubai courts earlier this year blake , who moved to dubai in september last year to take up a Â£ 100,000 - a - year - post at manpower recruitment firm , had been at a drink - all - you - like Â£ 35 - a - head brunch in the rotana hotel pakistani taxi driver qaiser khan , 29 , told the court in a statement the couple seemed confused and conor mcredmond swigged from a bottle â\\x80\\x99 mr qaiser khan said he pulled over , spotted a police patrol and called over emirati officer khamis , 22 , who said he found the pair still having sex she and mr conor mcredmond from tullamore , county offaly , were arrested on may 4 after meeting for the first time earlier that day in a hotel bar pakistani taxi driver qaiser khan , 29 , said he picked the couple up at around 11pm after their all - day drinking binge , which had started with midday brunch and unlimited drinks ms rebecca blake , who moved to dubai in september last year and worked for manpower recruitment firm until she was sacked after the incident in may , has said : ' i 'm no saint the whole incident was a blur ' the taxi driver claimed blake offered him â\\x80\\x98 a lot of money â\\x80\\x99 to tell prosecutors the pair were kissing rather than having sex but he refused fired : a tearful rebecca blake has lost her job at recruitment firm blake and conor mcredmond denied having consensual sex and indecency outrage : the couple 's lawyer shaker al shammary told dubai misdemeanours court the taxi driver made a malicious false accusation after rowing with mr conor mcredmond over the fare\""
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge1': Score(precision=0.42168674698795183, recall=0.1674641148325359, fmeasure=0.2397260273972603),\n",
       "  'rouge2': Score(precision=0.17073170731707318, recall=0.0673076923076923, fmeasure=0.09655172413793102),\n",
       "  'rougeL': Score(precision=0.26506024096385544, recall=0.10526315789473684, fmeasure=0.1506849315068493)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.4533333333333333, recall=0.06938775510204082, fmeasure=0.12035398230088495),\n",
       "  'rouge2': Score(precision=0.06756756756756757, recall=0.010224948875255624, fmeasure=0.017761989342806393),\n",
       "  'rougeL': Score(precision=0.25333333333333335, recall=0.03877551020408163, fmeasure=0.06725663716814159)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.7222222222222222, recall=0.031026252983293555, fmeasure=0.05949656750572082),\n",
       "  'rouge2': Score(precision=0.11764705882352941, recall=0.004784688995215311, fmeasure=0.009195402298850575),\n",
       "  'rougeL': Score(precision=0.4444444444444444, recall=0.01909307875894988, fmeasure=0.036613272311212815)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)},\n",
       " {'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       "  'rougeL': Score(precision=0, recall=0, fmeasure=0)}]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
