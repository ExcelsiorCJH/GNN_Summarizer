{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Summarizer Using PL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:26.240630Z",
     "start_time": "2020-04-14T06:05:21.220052Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from models import BasicSummarizerWithGDC\n",
    "from types_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:26.258586Z",
     "start_time": "2020-04-14T06:05:26.252599Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:26.913829Z",
     "start_time": "2020-04-14T06:05:26.904853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaExperiment Class with PL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:27.984966Z",
     "start_time": "2020-04-14T06:05:27.977985Z"
    }
   },
   "outputs": [],
   "source": [
    "# class SummaryDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, path):\n",
    "        \n",
    "#         with open(path, 'r', encoding='utf8') as f:\n",
    "#             self.data = [json.loads(line) for line in f]\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         \"\"\"Returns the number of data.\"\"\"\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         sentences = self.data[idx]['doc'].split('\\n')\n",
    "#         labels = self.data[idx]['labels'].split('\\n')\n",
    "#         labels = [int(label) for label in labels]\n",
    "        \n",
    "#         return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:28.485628Z",
     "start_time": "2020-04-14T06:05:28.461730Z"
    }
   },
   "outputs": [],
   "source": [
    "class SummaExperiment(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 model: BasicSummarizerWithGDC,\n",
    "                 params: dict) -> None:\n",
    "        \n",
    "        super(SummaExperiment, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        # self.curr_device = None\n",
    "        \n",
    "        \n",
    "    # ---------------------\n",
    "    # TRAINING\n",
    "    # ---------------------\n",
    "    def forward(self, docs, offsets, tdms, labels) -> Tensor:\n",
    "        return self.model(docs, offsets, tdms, labels)\n",
    "    \n",
    "    def loss_function(self, logits, labels):\n",
    "        labels = torch.cat(\n",
    "            [torch.tensor(label, dtype=torch.float) for label in labels]\n",
    "        )\n",
    "        labels = labels.view(-1, logits.size()[1]).to(DEVICE)\n",
    "        logits = logits.view(-1, logits.size()[1])\n",
    "        \n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        return bce_loss\n",
    "    \n",
    "    def accuracy(self, logits, labels):\n",
    "        \"\"\"Computes the accuracy for multiple binary predictions\"\"\"\n",
    "\n",
    "        labels = torch.cat(\n",
    "            [torch.tensor(label, dtype=torch.float) for label in labels]\n",
    "        )\n",
    "        labels = labels.view(-1, logits.size()[1]).to(DEVICE)\n",
    "        logits = logits.view(-1, logits.size()[1])\n",
    "\n",
    "        preds = torch.round(logits)\n",
    "        corrects = (preds == labels).sum().float()\n",
    "        acc = corrects / labels.numel()\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        docs, offsets, labels, tdms = batch\n",
    "        \n",
    "        logits = self.forward(docs, offsets, tdms, labels)\n",
    "        train_loss = self.loss_function(logits, labels)\n",
    "        train_acc = self.accuracy(logits, labels)\n",
    "        \n",
    "        tqdm_dict = {'train_acc': train_acc}\n",
    "        output = OrderedDict({\n",
    "            'loss': train_loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        docs, offsets, labels, tdms = batch\n",
    "        \n",
    "        logits = self.forward(docs, offsets, tdms, labels)\n",
    "        val_loss = self.loss_function(logits, labels)\n",
    "        \n",
    "        # acc\n",
    "        val_acc = self.accuracy(logits, labels)\n",
    "        \n",
    "        output = OrderedDict({\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Called at the end of validation to aggregate outputs\n",
    "        :param outputs: list of individual outputs of each validation step\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        val_loss_mean = 0\n",
    "        val_acc_mean = 0\n",
    "        for output in outputs:\n",
    "            val_loss_mean += output['val_loss']\n",
    "            val_acc_mean += output['val_acc']\n",
    "        \n",
    "        val_loss_mean /= len(outputs)\n",
    "        val_acc_mean /= len(outputs)\n",
    "        tqdm_dict = {'val_loss': val_loss_mean, 'val_acc': val_acc_mean}\n",
    "        result = {'progress_bar': tqdm_dict, 'log': tqdm_dict, 'val_loss': val_loss_mean}\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        docs, offsets, labels, tdms = batch\n",
    "        logits = self.forward(docs, offsets, tdms, labels)\n",
    "        test_loss = self.loss_function(logits, labels)\n",
    "        \n",
    "        # acc\n",
    "        test_acc = self.accuracy(logits, labels)\n",
    "        \n",
    "        output = OrderedDict({\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        test_loss_mean = 0\n",
    "        test_acc_mean = 0\n",
    "        for output in outputs:\n",
    "            test_loss_mean += output['test_loss']\n",
    "            test_acc_mean += output['test_acc']\n",
    "        \n",
    "        test_loss_mean /= len(outputs)\n",
    "        test_acc_mean /= len(outputs)\n",
    "        tqdm_dict = {'test_loss': test_loss_mean, 'test_acc': test_acc_mean}\n",
    "        result = {'progress_bar': tqdm_dict, 'log': tqdm_dict, 'test_loss': test_loss_mean}\n",
    "        return result\n",
    "    \n",
    "    # ---------------------\n",
    "    # TRAINING SETUP\n",
    "    # ---------------------\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=self.params['LR'],\n",
    "                               weight_decay=self.params['weight_decay'])\n",
    "        \n",
    "        return [optimizer]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def __collate_fn(batch):\n",
    "        docs = [entry[0] for entry in batch]\n",
    "        labels = [entry[1] for entry in batch]\n",
    "        tdms = [entry[2] for entry in batch]\n",
    "        offsets = [0] + [len(doc) for doc in docs]\n",
    "        return docs, offsets, labels, tdms\n",
    "    \n",
    "    def __dataloader(self, phase='train'):\n",
    "        \n",
    "        train_path = '../../data/summary/data/train.json'\n",
    "        valid_path = '../../data/summary/data/val.json'\n",
    "        test_path = '../../data/summary/data/test.json'\n",
    "\n",
    "        trainset = SummaryDataset(train_path)\n",
    "        validset = SummaryDataset(valid_path)\n",
    "        testset = SummaryDataset(test_path)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            loader =  DataLoader(trainset, \n",
    "                                 batch_size=self.params['batch_size'], \n",
    "                                 shuffle=False, \n",
    "                                 collate_fn=self.__collate_fn)\n",
    "        elif phase == 'valid':\n",
    "            loader =  DataLoader(validset, \n",
    "                                 batch_size=self.params['batch_size'], \n",
    "                                 shuffle=False, \n",
    "                                 collate_fn=self.__collate_fn)\n",
    "        elif phase == 'test':\n",
    "            loader =  DataLoader(testset, \n",
    "                                 batch_size=self.params['batch_size'], \n",
    "                                 shuffle=False, \n",
    "                                 collate_fn=self.__collate_fn)\n",
    "        \n",
    "        return loader\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # log.info('Training data loader called.')\n",
    "        print('Training data loader called.')\n",
    "        return self.__dataloader(phase='train')\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        # log.info('Validation data loader called.')\n",
    "        print('Validation data loader called.')\n",
    "        return self.__dataloader(phase='valid')\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        # log.info('Test data loader called.')\n",
    "        print('Test data loader called.')\n",
    "        return self.__dataloader(phase='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Summary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    docs = [entry[0] for entry in batch]\n",
    "    labels = [entry[1] for entry in batch]\n",
    "    tdms = [entry[2] for entry in batch]\n",
    "    \n",
    "    offsets = [0] + [len(doc) for doc in docs]\n",
    "        \n",
    "    return docs, offsets, labels, tdms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data.\"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.data[idx]['doc'].split('\\n')\n",
    "        labels = self.data[idx]['labels'].split('\\n')\n",
    "        labels = [int(label) for label in labels]\n",
    "        \n",
    "        tfidf = TfidfVectorizer().fit(sentences)\n",
    "        tdm = tfidf.transform(sentences).toarray()\n",
    "        \n",
    "        return sentences, labels, tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:37.299066Z",
     "start_time": "2020-04-14T06:05:31.840695Z"
    }
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'batch_size' : 32,\n",
    "    'LR': 0.005,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "model = BasicSummarizerWithGDC(in_dim=128,\n",
    "                               hidden_dim=64,\n",
    "                               out_dim=32,\n",
    "                               num_heads=2,\n",
    "                               num_classes=1,\n",
    "                               use_gdc=True).to(DEVICE)\n",
    "experiment = SummaExperiment(model, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:37.326991Z",
     "start_time": "2020-04-14T06:05:37.318016Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='./checkpoints/basicsummarizerGDC_{epoch:02d}_{val_acc:.2f}_lr005_v02',\n",
    "    monitor='val_acc',\n",
    "    verbose=True,\n",
    "    save_top_k=5,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20,\n",
    "                     checkpoint_callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-14T06:05:38.098Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T06:05:30.568059Z",
     "start_time": "2020-04-14T06:05:30.561082Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.CNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at C:\\Users\\korea\\.cache\\torch\\transformers\\dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n"
     ]
    }
   ],
   "source": [
    "hparams = {\n",
    "    'batch_size' : 32,\n",
    "    'LR': 0.005,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "model = BasicSummarizer(in_dim=128,\n",
    "                        hidden_dim=64,\n",
    "                        out_dim=32,\n",
    "                        num_heads=2,\n",
    "                        num_classes=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SummaExperiment(model, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(resume_from_checkpoint='./checkpoints/basicsummarizer_epoch=18_val_acc=0.62_lr005_v02.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loader called.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e642cce2db674db59e2047c65ee9d44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing', layout=Layout(flex='2'), max=1213.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': 0.6256545782089233, 'test_loss': 0.7528885006904602}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './save_weights/basicsumarizer_epoch=18_val_acc=0.62_lr005.pth'\n",
    "# torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at C:\\Users\\korea\\.cache\\torch\\transformers\\dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = {\n",
    "    'batch_size' : 32,\n",
    "    'LR': 0.005,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "model = BasicSummarizer(in_dim=128,\n",
    "                        hidden_dim=64,\n",
    "                        out_dim=32,\n",
    "                        num_heads=2,\n",
    "                        num_classes=1).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = SummaExperiment(model, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loader called.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7123058464034ceaaebc5ef776dc3180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing', layout=Layout(flex='2'), max=1213.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': 0.6236557960510254, 'test_loss': 0.7534582614898682}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "trainer.test(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
