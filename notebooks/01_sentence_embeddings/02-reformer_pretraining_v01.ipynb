{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformer Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import dill\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from barbar import Bar\n",
    "\n",
    "from reformer_pytorch import Reformer, ReformerLM\n",
    "from transformers import BertTokenizer, PreTrainedTokenizer\n",
    "from fairseq.optim.adafactor import Adafactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Create WikiDataset\n",
    "\n",
    "- Reformer를 pretrain 하기 위해 SentDataset 클래스를 만들어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, prefix=\"train\", is_sample=False):\n",
    "        \n",
    "        with open(path, 'rb') as f:\n",
    "            self.corpus = dill.load(f)\n",
    "            if is_sample:\n",
    "                self.corpus = self.corpus[:1000]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of corpus.\"\"\"\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.corpus[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SentDataset \n",
    "corpus_path = '../data/corpus/kowiki_corpus.pkl'\n",
    "\n",
    "dataset = SentDataset(corpus_path, prefix='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len : 4353763\n",
      "수학의 기초에 대한 위기는 그 당시 수많은 논쟁에 의해 촉발되었으며, 그 논쟁에는 칸토어의 집합론과 브라우어-힐베르트 논쟁이 포함되었다.\n",
      "['지미 카터 제임스 얼 \"지미\" 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ '\n",
      " '1981년)이다.',\n",
      " '지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.',\n",
      " '조지아 공과대학교를 졸업하였다.']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print('len :', len(dataset))\n",
    "print(dataset[100])\n",
    "pprint(dataset[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. ReformerTrainer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BERT와 마찬가지로 Pretraining 단계에서 MLM(Masked-Language Model) Task를 이용해 학습시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReformerTrainer:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dataset, \n",
    "                 model, \n",
    "                 tokenizer,\n",
    "                 device=None, \n",
    "                 train_batch_size=8, \n",
    "                 eval_batch_size=None, \n",
    "                 tb_writer=True, \n",
    "                 tb_dir='./tb_logs', \n",
    "                 log_dir='./logs'):\n",
    "        \"\"\"\n",
    "        Provides an easy to use class for pretraining and evaluating a Reformer Model.\n",
    "        \n",
    "        :param dataset: (torch.utils.data.Dataset) containing all of the data you wish to utilize during training.\n",
    "        :param model: (reformer_pytorch.Reformer)\n",
    "        :param tokenizer: (transformers.PreTrainedTokenizer) defaults to BertTokenizer ('bert-base-case')\n",
    "        :param device: provide manual device placement. If None, will default to cuda:0 if available.\n",
    "        :param tb_writer: (bool) Whether to write to tensorboard or not.\n",
    "        :param tb_dir: (str) Where to write TB logs to.\n",
    "        :param log_dir: (str) Where to write generic logs to.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.tb_writer = tb_writer\n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "        self.err_cnt = 0\n",
    "        \n",
    "        if not tokenizer:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual')\n",
    "            \n",
    "        if not device:\n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "            \n",
    "        if not eval_batch_size:\n",
    "            self.eval_batch_size = train_batch_size\n",
    "            \n",
    "        if tb_writer:\n",
    "            from torch.utils.tensorboard import SummaryWriter\n",
    "            self.writer = SummaryWriter(log_dir=tb_dir)\n",
    "            \n",
    "        logging.basicConfig(filename=f'{log_dir}/{datetime.now().date()}.log', level=logging.INFO)\n",
    "        \n",
    "        \n",
    "    def build_dataloaders(self, train_test_split=0.1, train_shuffle=True, eval_shuffle=True):\n",
    "        \"\"\"\n",
    "        Builds the Training and Eval DataLoaders\n",
    "        \n",
    "        :param train_test_split: The ratio split of test to train data.\n",
    "        :param train_shuffle: (bool) True if you wish to shuffle the train_dataset.\n",
    "        :param eval_shuffle: (bool) True if you wish to shuffle the eval_dataset.\n",
    "        :return: train dataloader and evaluation dataloader.\n",
    "        \"\"\"\n",
    "        dataset_len = len(self.dataset)\n",
    "        eval_len = int(dataset_len * train_test_split)\n",
    "        train_len = dataset_len - eval_len\n",
    "        train_dataset, eval_dataset = random_split(self.dataset, (train_len, eval_len))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.train_batch_size, shuffle=train_shuffle)\n",
    "        eval_loader = DataLoader(eval_dataset, batch_size=self.eval_batch_size, shuffle=eval_shuffle)\n",
    "        logging.info(f'''train_dataloader size: {len(train_loader.dataset)} | shuffle: {train_shuffle}\n",
    "                         eval_dataloader size: {len(eval_loader.dataset)} | shuffle: {eval_shuffle}''')\n",
    "        \n",
    "        return train_loader, eval_loader\n",
    "    \n",
    "    \n",
    "    def mask_tokens(self, inputs: torch.Tensor, mlm_probability=0.15, pad=True):\n",
    "        \"\"\" \n",
    "        Prepare masked tokens inputs/labels for masked language modeling: \n",
    "            -> 80% MASK, 10% random, 10% original. \n",
    "        \"\"\"\n",
    "        labels = inputs.clone()\n",
    "        # mlm_probability defaults to 0.15 in Bert\n",
    "        probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "        special_tokens_mask = [\n",
    "            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "        ]\n",
    "        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "        \n",
    "        if self.tokenizer._pad_token is not None:\n",
    "            padding_mask = labels.eq(self.tokenizer.pad_token_id)\n",
    "            probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "        \n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "        \n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "        \n",
    "        if pad:\n",
    "            input_pads = self.tokenizer.max_len - inputs.shape[-1]\n",
    "            label_pads = self.tokenizer.max_len - labels.shape[-1]\n",
    "            \n",
    "            inputs = F.pad(inputs, pad=(0, input_pads), value=self.tokenizer.pad_token_id)\n",
    "            labels = F.pad(labels, pad=(0, label_pads), value=self.tokenizer.pad_token_id)\n",
    "            \n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels\n",
    "    \n",
    "    \n",
    "    def _tokenize_input_ids(self, input_ids: list, pad_to_max_length: bool = True):\n",
    "        \"\"\"\n",
    "        Helper function to clean up the train and eval functions\n",
    "        \n",
    "        :param input_ids: inputs to tokenize.\n",
    "        :param pad_to_max_length: Whether you want to pad the inputs to the tokenizer.max_len\n",
    "        :return: Tensor containing training data.\n",
    "        \"\"\"\n",
    "        inputs = torch.cat(\n",
    "            [\n",
    "                self.tokenizer.encode(\n",
    "                    input_ids[i],\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.tokenizer.max_len,\n",
    "                    pad_to_max_length=pad_to_max_length,\n",
    "                    return_tensors='pt'\n",
    "                )  \n",
    "                for i in range(len(input_ids))\n",
    "            ]\n",
    "        )\n",
    "        return inputs\n",
    "    \n",
    "    \n",
    "    def train(self,\n",
    "              epochs, \n",
    "              train_dataloader,\n",
    "              eval_dataloader,\n",
    "              log_steps,\n",
    "              ckpt_steps,\n",
    "              ckpt_dir=None,\n",
    "              gradient_accumulation_steps=1):\n",
    "        \"\"\"\n",
    "        Trains the Reformer Model\n",
    "        \n",
    "        :param epochs: The number of times you wish to loop through the dataset.\n",
    "        :param train_dataloader: (torch.utils.data.DataLoader) The data to train on.\n",
    "        :param eval_dataloader: (torch.utils.data.DataLoader) The data to evaluate on.\n",
    "        :param log_steps: The number of steps to iterate before logging.\n",
    "        :param ckpt_steps: The number of steps to iterate before checkpointing.\n",
    "        :param ckpt_dir: The directory to save the checkpoints to.\n",
    "        :param gradient_accumulation_steps: Optional gradient accumulation.\n",
    "        :return: Total number of steps, total loss, model\n",
    "        \"\"\"\n",
    "        \n",
    "        optimizer = Adafactor(self.model.parameters())\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        losses = {}\n",
    "        global_steps = 0\n",
    "        local_steps = 0\n",
    "        step_loss = 0.0\n",
    "        \n",
    "        if ckpt_dir:\n",
    "            assert os.path.isdir(ckpt_dir)\n",
    "            try:\n",
    "                logging.info(f'{datetime.now()} | Continuing from checkpoint...')\n",
    "                self.model.load_state_dict(torch.load(f'{ckpt_dir}/model_state_dict.pt', map_location=self.device))\n",
    "                optimizer.load_state_dict(torch.load(f'{ckpt_dir}/optimizer_state_dict.pt'))\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.info(f'{datetime.now()} | No checkpoint was found | {e}')\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        if self.n_gpu > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "            logging.info(f'{datetime.now()} | Utilizing {self.n_gpu} GPUs')\n",
    "            \n",
    "        self.model.to(self.device)\n",
    "        logging.info(f'{datetime.now()} | Moved model to: {self.device}')\n",
    "        logging.info(\n",
    "            f'{datetime.now()} | train_batch_size: {self.train_batch_size} | eval_batch_size: {self.eval_batch_size}')\n",
    "        logging.info(f'{datetime.now()} | Epochs: {epochs} | log_steps: {log_steps} | ckpt_steps: {ckpt_steps}')\n",
    "        logging.info(f'{datetime.now()} | gradient_accumulation_steps: {gradient_accumulation_steps}')\n",
    "        \n",
    "        for epoch in tqdm(range(epochs), desc='Epochs', position=0):\n",
    "            logging.info(f'{datetime.now()} | Epoch: {epoch}')\n",
    "            for step, batch in tqdm(enumerate(train_dataloader),\n",
    "                                    desc='Epoch Iterator',\n",
    "                                    position=1,\n",
    "                                    leave=True,\n",
    "                                    total=len(train_dataloader)):\n",
    "                for data in batch:\n",
    "                    inputs = self._tokenize_input_ids(data, pad_to_max_length=True)\n",
    "                    inputs, labels = self.mask_tokens(inputs)\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    output = self.model(inputs)\n",
    "                    \n",
    "                    # only calculating loss on masked tokens\n",
    "                    loss_mx = labels != -100\n",
    "                    output = output[loss_mx].view(-1, self.tokenizer.vocab_size)\n",
    "                    labels = labels[loss_mx].view(-1)\n",
    "                    \n",
    "                    try:\n",
    "                        loss = loss_fn(output, labels)\n",
    "                    except:\n",
    "                        self.err_cnt += 1\n",
    "                        continue\n",
    "                    \n",
    "                    if gradient_accumulation_steps > 1:\n",
    "                        loss /= gradient_accumulation_steps\n",
    "                        \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    self.model.zero_grad()\n",
    "                    \n",
    "                    step_loss += loss.item()\n",
    "                    losses[global_steps] = loss.item()\n",
    "                    local_steps += 1\n",
    "                    global_steps += 1\n",
    "                    \n",
    "                    if global_steps % log_steps == 0:\n",
    "                        if self.tb_writer:\n",
    "                            self.writer.add_scalar('Train/Loss', step_loss / local_steps, global_steps)\n",
    "                            self.writer.close()\n",
    "                        logging.info(\n",
    "                            f'''{datetime.now()} | Train Loss: {step_loss / local_steps} | Steps: {global_steps}''')\n",
    "                        # on jupyter notebook\n",
    "                        print(f'{datetime.now()} | Train Loss: {step_loss / local_steps} | Steps: {global_steps}')\n",
    "\n",
    "                        with open(f'{self.log_dir}/train_results.json', 'w') as results_file:\n",
    "                            json.dump(losses, results_file)\n",
    "                            results_file.close()\n",
    "                        step_loss = 0.0\n",
    "                        local_steps = 0\n",
    "                        \n",
    "                    if global_steps % ckpt_steps == 0:\n",
    "                        # evaluating before every checkpoint\n",
    "                        self.evaluate(eval_dataloader)\n",
    "                        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "                        torch.save(model_to_save.state_dict(), f'{ckpt_dir}/model_state_dict.pt')\n",
    "                        torch.save(optimizer.state_dict(), f'{ckpt_dir}/optimizer_state_dict.pt')\n",
    "\n",
    "                        logging.info(f'{datetime.now()} | Saved checkpoint to: {ckpt_dir}')\n",
    "                        # on jupyter notebook\n",
    "                        print(f'{datetime.now()} | Saved checkpoint to: {ckpt_dir}')\n",
    "\n",
    "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        torch.save(model_to_save.state_dict(), f'{ckpt_dir}/model_state_dict.pt')\n",
    "        torch.save(optimizer.state_dict(), f'{ckpt_dir}/optimizer_state_dict.pt')\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    def evaluate(self, dataloader):\n",
    "        \"\"\"\n",
    "        Runs through the provided dataloader with torch.no_grad()\n",
    "        :param dataloader: (torch.utils.data.DataLoader) Evaluation DataLoader\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        if self.n_gpu > 1 and not isinstance(self.model, nn.DataParallel):\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "        self.model.eval()\n",
    "        eval_loss = 0.0\n",
    "        perplexity = 0.0\n",
    "        eval_steps = 0\n",
    "\n",
    "        logging.info(f'{datetime.now()} | Evaluating...')\n",
    "        for step, batch in tqdm(enumerate(dataloader), desc='Evaluating', leave=True, total=len(dataloader)):\n",
    "            for data in batch:\n",
    "                inputs = self._tokenize_input_ids(data, pad_to_max_length=True)\n",
    "                inputs, labels = self.mask_tokens(inputs)\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = self.model(inputs)\n",
    "\n",
    "                loss_mx = labels != -100\n",
    "                output_ids = output[loss_mx].view(-1, self.tokenizer.vocab_size)\n",
    "                labels = labels[loss_mx].view(-1)\n",
    "                try:\n",
    "                    tmp_eval_loss = loss_fn(output_ids, labels)\n",
    "                    tmp_perplexity = torch.exp(tmp_eval_loss)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if self.n_gpu > 1:\n",
    "                    tmp_eval_loss = tmp_eval_loss.mean()\n",
    "\n",
    "                eval_loss += tmp_eval_loss.item()\n",
    "                perplexity += tmp_perplexity.item()\n",
    "                eval_steps += 1\n",
    "\n",
    "            eval_loss /= eval_steps\n",
    "            perplexity /= eval_steps\n",
    "\n",
    "            if self.tb_writer:\n",
    "                self.writer.add_scalar('Eval/Loss', eval_loss, eval_steps)\n",
    "                self.writer.close()\n",
    "                self.writer.add_scalar('Perplexity', perplexity, eval_steps)\n",
    "                self.writer.close()\n",
    "            logging.info(f'{datetime.now()} | Step: {step} | Eval Loss: {eval_loss} | Perplexity: {perplexity}')\n",
    "            # on jupyter notebook\n",
    "            print(f'{datetime.now()} | Step: {step} | Eval Loss: {eval_loss} | Perplexity: {perplexity}')\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Reformer Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "corpus_path = '../data/corpus/kowiki_corpus.pkl'\n",
    "dataset = SentDataset(corpus_path, prefix='train', is_sample=False)\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = BertTokenizer(vocab_file='../data/tokenizers/vocab.txt', max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformer model\n",
    "model = ReformerLM(num_tokens=tokenizer.vocab_size, \n",
    "                   dim=128,\n",
    "                   depth=2,\n",
    "                   heads=4,\n",
    "                   max_seq_len=tokenizer.max_len,\n",
    "                   causal=True)\n",
    "\n",
    "# Reformer trainer\n",
    "trainer = ReformerTrainer(dataset, model, tokenizer, train_batch_size=16, eval_batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_dataloader, eval_dataloader = trainer.build_dataloaders(train_test_split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cda0ddbd2b4d3b84b6377e71df9842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=3.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1069abf60bd744d181bf608ed5f70cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch Iterator', max=81634.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-27 23:07:01.904178 | Train Loss: 7.291672611236573 | Steps: 10\n",
      "2020-02-27 23:07:04.214092 | Train Loss: 7.096446228027344 | Steps: 20\n",
      "2020-02-27 23:07:06.540395 | Train Loss: 7.062275791168213 | Steps: 30\n",
      "2020-02-27 23:07:08.550807 | Train Loss: 7.3383701801300045 | Steps: 40\n",
      "2020-02-27 23:07:10.689869 | Train Loss: 6.73081784248352 | Steps: 50\n",
      "2020-02-27 23:07:12.850235 | Train Loss: 6.719512844085694 | Steps: 60\n",
      "2020-02-27 23:07:14.910003 | Train Loss: 6.49729552268982 | Steps: 70\n",
      "2020-02-27 23:07:17.171815 | Train Loss: 7.090572738647461 | Steps: 80\n",
      "2020-02-27 23:07:19.888384 | Train Loss: 7.030154180526734 | Steps: 90\n",
      "2020-02-27 23:07:22.194033 | Train Loss: 6.757112455368042 | Steps: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42eee4f60081474ba5c1d6a3d9a8119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=190478.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-27 23:07:23.571068 | Step: 0 | Eval Loss: 6.099507451057434 | Perplexity: 712.0365476608276\n",
      "2020-02-27 23:07:24.736822 | Step: 1 | Eval Loss: 3.3500425554811954 | Perplexity: 720.228413194418\n",
      "2020-02-27 23:07:25.931552 | Step: 2 | Eval Loss: 2.3110198323459676 | Perplexity: 941.100036871309\n",
      "2020-02-27 23:07:27.250821 | Step: 3 | Eval Loss: 1.6597326462227406 | Perplexity: 290.00441790018033\n",
      "2020-02-27 23:07:28.424464 | Step: 4 | Eval Loss: 1.1818289976391088 | Perplexity: 113.16880798948384\n",
      "2020-02-27 23:07:29.737773 | Step: 5 | Eval Loss: 1.070081655248971 | Perplexity: 263.14898527435935\n",
      "2020-02-27 23:07:30.940493 | Step: 6 | Eval Loss: 0.9710993935128502 | Perplexity: 3851.450882706929\n",
      "2020-02-27 23:07:31.985065 | Step: 7 | Eval Loss: 0.7200428892139565 | Perplexity: 92.38166014947817\n",
      "2020-02-27 23:07:33.114093 | Step: 8 | Eval Loss: 0.7288879723119092 | Perplexity: 221.65422686504914\n",
      "2020-02-27 23:07:34.325670 | Step: 9 | Eval Loss: 0.6446824477259414 | Perplexity: 75.48869134558451\n",
      "2020-02-27 23:07:35.635741 | Step: 10 | Eval Loss: 0.6217943418563463 | Perplexity: 124.79771056129405\n",
      "2020-02-27 23:07:36.907069 | Step: 11 | Eval Loss: 0.5697634577691246 | Perplexity: 140.51356689126627\n",
      "2020-02-27 23:07:38.204310 | Step: 12 | Eval Loss: 0.5229118925274864 | Perplexity: 171.15945587304765\n",
      "2020-02-27 23:07:39.500609 | Step: 13 | Eval Loss: 0.41239377971415675 | Perplexity: 67.62867232621109\n",
      "2020-02-27 23:07:40.553662 | Step: 14 | Eval Loss: 0.463739356793261 | Perplexity: 226.82399089311497\n",
      "2020-02-27 23:07:41.845440 | Step: 15 | Eval Loss: 0.3835019554914273 | Perplexity: 51.92387815737344\n",
      "2020-02-27 23:07:43.070280 | Step: 16 | Eval Loss: 0.3784609335381085 | Perplexity: 59.95328191474555\n",
      "2020-02-27 23:07:44.329287 | Step: 17 | Eval Loss: 0.3927468017171413 | Perplexity: 1003.4598233023428\n",
      "2020-02-27 23:07:45.583584 | Step: 18 | Eval Loss: 0.35388085016889775 | Perplexity: 62.42869631136478\n",
      "2020-02-27 23:07:46.740585 | Step: 19 | Eval Loss: 0.31953329533461655 | Perplexity: 69.5789621415225\n",
      "2020-02-27 23:07:47.922832 | Step: 20 | Eval Loss: 0.28757062861628935 | Perplexity: 84.53897585870706\n",
      "2020-02-27 23:07:49.259233 | Step: 21 | Eval Loss: 0.2941291966917103 | Perplexity: 50.61629439263514\n",
      "2020-02-27 23:07:50.380215 | Step: 22 | Eval Loss: 0.2755150436478662 | Perplexity: 46.13547021087461\n",
      "2020-02-27 23:07:52.018353 | Step: 23 | Eval Loss: 0.2741952449708439 | Perplexity: 66.03030491078988\n",
      "2020-02-27 23:07:53.233928 | Step: 24 | Eval Loss: 0.2674928043904703 | Perplexity: 378.71566914549294\n",
      "2020-02-27 23:07:54.437051 | Step: 25 | Eval Loss: 0.22587800788149995 | Perplexity: 32.84976190137725\n",
      "2020-02-27 23:07:55.584951 | Step: 26 | Eval Loss: 0.24993259009598537 | Perplexity: 89.97496150625506\n",
      "2020-02-27 23:07:56.834939 | Step: 27 | Eval Loss: 0.24021015839467222 | Perplexity: 62.797960033754165\n",
      "2020-02-27 23:07:58.045412 | Step: 28 | Eval Loss: 0.2557934478007005 | Perplexity: 1090.15342779397\n",
      "2020-02-27 23:07:59.473803 | Step: 29 | Eval Loss: 0.2258098444764042 | Perplexity: 44.76643593844984\n",
      "2020-02-27 23:08:00.522097 | Step: 30 | Eval Loss: 0.18166626798298546 | Perplexity: 30.562010287908148\n",
      "2020-02-27 23:08:01.822244 | Step: 31 | Eval Loss: 0.20866682484809296 | Perplexity: 30.08595571706725\n",
      "2020-02-27 23:08:03.012314 | Step: 32 | Eval Loss: 0.21404559511512697 | Perplexity: 83.8809758570775\n",
      "2020-02-27 23:08:04.541658 | Step: 33 | Eval Loss: 0.1809843530831825 | Perplexity: 35.55181549225336\n",
      "2020-02-27 23:08:06.156315 | Step: 34 | Eval Loss: 0.19550871131907088 | Perplexity: 35.242797569056535\n",
      "2020-02-27 23:08:07.392290 | Step: 35 | Eval Loss: 0.18358900806010625 | Perplexity: 28.420823459396516\n",
      "2020-02-27 23:08:08.680725 | Step: 36 | Eval Loss: 0.162990390993049 | Perplexity: 22.004743705899614\n",
      "2020-02-27 23:08:10.002483 | Step: 37 | Eval Loss: 0.17678595833026256 | Perplexity: 257.3811417678938\n",
      "2020-02-27 23:08:11.316451 | Step: 38 | Eval Loss: 0.16982266187751913 | Perplexity: 22.331156226848837\n",
      "2020-02-27 23:08:12.417630 | Step: 39 | Eval Loss: 0.1493128883366364 | Perplexity: 19.019049338375105\n",
      "2020-02-27 23:08:14.140445 | Step: 40 | Eval Loss: 0.15672942609831278 | Perplexity: 21.61139975917621\n",
      "2020-02-27 23:08:15.375055 | Step: 41 | Eval Loss: 0.15293445085824772 | Perplexity: 20.578732099452353\n",
      "2020-02-27 23:08:16.530935 | Step: 42 | Eval Loss: 0.15256718212057901 | Perplexity: 21.841549718278028\n",
      "2020-02-27 23:08:17.876267 | Step: 43 | Eval Loss: 0.14365804766313192 | Perplexity: 19.939096635828626\n",
      "2020-02-27 23:08:19.122342 | Step: 44 | Eval Loss: 0.15019163284755985 | Perplexity: 46.825832568400706\n",
      "2020-02-27 23:08:20.468473 | Step: 45 | Eval Loss: 0.15274256078098927 | Perplexity: 175.03082418666253\n",
      "2020-02-27 23:08:21.622404 | Step: 46 | Eval Loss: 0.1439749089845751 | Perplexity: 29.85465946107964\n",
      "2020-02-27 23:08:22.973257 | Step: 47 | Eval Loss: 0.14286431416116172 | Perplexity: 35.25000062246293\n",
      "2020-02-27 23:08:24.288419 | Step: 48 | Eval Loss: 0.1340461006054858 | Perplexity: 23.16600948291003\n",
      "2020-02-27 23:08:25.479479 | Step: 49 | Eval Loss: 0.13951901271157982 | Perplexity: 49.730095490263395\n",
      "2020-02-27 23:08:26.680124 | Step: 50 | Eval Loss: 0.1218965851693621 | Perplexity: 13.20906041440621\n",
      "2020-02-27 23:08:27.854461 | Step: 51 | Eval Loss: 0.13046313442690324 | Perplexity: 22.561598646519798\n",
      "2020-02-27 23:08:29.087500 | Step: 52 | Eval Loss: 0.12484254826992978 | Perplexity: 17.918080034201846\n",
      "2020-02-27 23:08:30.330586 | Step: 53 | Eval Loss: 0.11331606234711618 | Perplexity: 9.838869673399834\n",
      "2020-02-27 23:08:31.527111 | Step: 54 | Eval Loss: 0.12182607005126078 | Perplexity: 23.30259757431356\n",
      "2020-02-27 23:08:32.542688 | Step: 55 | Eval Loss: 0.10815839562214802 | Perplexity: 25.64691700359939\n",
      "2020-02-27 23:08:33.952237 | Step: 56 | Eval Loss: 0.11109446823501576 | Perplexity: 12.259174953431055\n",
      "2020-02-27 23:08:35.278294 | Step: 57 | Eval Loss: 0.11098206587931067 | Perplexity: 20.282787660249667\n",
      "2020-02-27 23:08:36.425978 | Step: 58 | Eval Loss: 0.10888621447756303 | Perplexity: 20.53273225530428\n",
      "2020-02-27 23:08:37.588795 | Step: 59 | Eval Loss: 0.10724968505782281 | Perplexity: 16.308220393790535\n",
      "2020-02-27 23:08:38.858837 | Step: 60 | Eval Loss: 0.09688001093667696 | Perplexity: 12.165656854212113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33eeb3facc6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mckpt_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mckpt_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./ckpts'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                       gradient_accumulation_steps=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ckpts/model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a39f9564a3a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_dataloader, eval_dataloader, log_steps, ckpt_steps, ckpt_dir, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mglobal_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mckpt_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0;31m# evaluating before every checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                         \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{ckpt_dir}/model_state_dict.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a39f9564a3a4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mloss_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_model_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, keys)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_reversible_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/revtorch/revtorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         '''\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ReversibleModuleFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreversible_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meagerly_discard_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/revtorch/revtorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, reversible_blocks, eagerly_discard_variables)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversible_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReversibleBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#not using ctx.save_for_backward(x) saves us memory by beeing able to free ctx.y earlier in the backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreversible_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreversible_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/revtorch/revtorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_along_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSettableArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSettableArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/reformer_pytorch/reformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;31m# reformer lm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the Reformer\n",
    "model = trainer.train(epochs=3,\n",
    "                      train_dataloader=train_dataloader,\n",
    "                      eval_dataloader=eval_dataloader,\n",
    "                      log_steps=10,\n",
    "                      ckpt_steps=100,\n",
    "                      ckpt_dir='./ckpts',\n",
    "                      gradient_accumulation_steps=1)\n",
    "torch.save(model, './ckpts/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
